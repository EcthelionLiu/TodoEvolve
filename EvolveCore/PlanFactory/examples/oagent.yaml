python_code: |-
  <<<PYTHON>>>
  import textwrap
  from typing import Any, Callable, Dict, List, Optional
  from jinja2 import StrictUndefined, Template

  from ..memory import ActionStep, AgentMemory, PlanningStep, SummaryStep
  from ..models import ChatMessage, MessageRole
  from ..monitoring import AgentLogger, LogLevel
  from ..tools import Tool
  from rich.rule import Rule
  from rich.text import Text
  from .base_planning import BasePlanning

  def populate_template(template: str, variables: Dict[str, Any]) -> str:
      compiled_template = Template(template, undefined=StrictUndefined)
      try:
          return compiled_template.render(**variables)
      except Exception as e:
          raise Exception(f"Error during jinja template rendering: {type(e).__name__}: {e}")


  class PlannerPlanning(BasePlanning):
      def __init__(
          self,
          model: Callable[[List[Dict[str, str]]], ChatMessage],
          tools: Dict[str, Tool],
          prompt_templates: Dict[str, Any],
          memory: AgentMemory,
          logger: AgentLogger
      ):
          super().__init__(model, tools, prompt_templates, memory, logger)

      def topology_initialize(self, task: str) -> PlanningStep:
          """
          Generate initial task plan and record to memory and logger.

          This method replaces the MultiStepAgent.planning_step() method with identical functionality:
          1. Build planning prompt messages
          2. Call LLM to generate plan
          3. Extract plan content and reasoning process
          4. Record to memory (via self.memory.steps.append)
          5. Output to logger (via self.logger.log)

          Args:
              task: Task description to execute

          Returns:
              PlanningStep: Step object containing plan information with fields:
                  - model_input_messages: Message list sent to model
                  - plan: Generated plan text
                  - plan_think: Plan thinking content (currently empty string)
                  - plan_reasoning: Model reasoning content
          """
          # Build system prompt messages
          input_messages = [
              {
                  "role": MessageRole.SYSTEM,
                  "content": [
                      {
                          "type": "text",
                          "text": populate_template(
                              self.prompt_templates["planning"]["initial_plan"],
                              variables={
                                  "tools": self.tools,
                              },
                          ),
                      }
                  ],
              },
          ]

          # Build task input messages
          task_messages = [{
              "role": MessageRole.USER,
              "content": [{"type": "text", "text": populate_template(self.prompt_templates["planning"]["task_input"], variables={"task": task})}],
          }]

          # Call model to generate plan
          chat_message_plan: ChatMessage = self.model(input_messages + task_messages)
          think_content = chat_message_plan.reasoning_content
          plans = chat_message_plan.content
          plans_think, plans_answer = "", plans

          # Format plan text for log output
          final_plan_redaction = textwrap.dedent(
              f"""Here is the plan of action that I will follow to solve the task:\n```\n{plans_answer}\n```\n"""
          )

          # Output to logger
          self.logger.log(
              Rule("[bold]Initial plan", style="orange"),
              Text(final_plan_redaction),
              level=LogLevel.INFO,
          )

          # Create PlanningStep object
          planning_step = PlanningStep(
              model_input_messages=input_messages,
              plan=plans_answer,
              plan_think=plans_think,
              plan_reasoning=think_content,
          )

          # Record to memory
          self.memory.steps.append(planning_step)

          return planning_step


      def adaptation(
          self,
          task: str,
          step: int,
          write_memory_to_messages: Callable[[Optional[List[ActionStep]], Optional[bool]], List[Dict[str, str]]]
      ) -> SummaryStep:
          # Read execution history from memory (skip system prompt)
          memory_messages = write_memory_to_messages(None, False)[1:]

          # Build summary prompt pre and post messages
          update_pre_messages = {
              "role": MessageRole.SYSTEM,
              "content": [{"type": "text", "text": self.prompt_templates["summary"]["update_pre_messages"]}],
          }
          update_post_messages = {
              "role": MessageRole.USER,
              "content": [{"type": "text", "text": self.prompt_templates["summary"]["update_post_messages"]}],
          }

          # Combine complete input messages
          input_messages = [update_pre_messages] + memory_messages + [update_post_messages]

          # Call model to generate summary
          chat_message_summary: ChatMessage = self.model(input_messages)

          summary_answer = chat_message_summary.content
          summary_cot_content = chat_message_summary.reasoning_content

          # Format summary text for log output
          final_summary_redaction = textwrap.dedent(
              f"""
              Here is my summary of action to solve the task:
              ```
              {summary_answer}
              ```"""
          )

          # Create SummaryStep object
          summary_step = SummaryStep(
              model_input_messages=input_messages,
              summary=summary_answer,
              summary_reasoning=summary_cot_content,
          )

          # Record to memory
          self.memory.steps.append(summary_step)

          # Output to logger
          self.logger.log(
              Rule("[bold]Summary", style="orange"),
              Text(final_summary_redaction),
              level=LogLevel.INFO,
          )

          return summary_step
  <<<END_PYTHON>>>
yaml_config: |-
  <<<YAML>>>
  system_prompt: |-
    You are an open-world task-solving assistant to solve tasks through structured tool calls.
  
    You operate in an iterative Action/Observation loop:
    - You propose one Action as a JSON object with:
      - "think": detailed reasoning in English (needs analysis, tool choice, execution plan, verification plan)
      - "tools": a list of tool calls, each with "name" and "arguments" (matching the tool schema)
    - After tool execution, you will receive Observations that you must use in subsequent Actions.
  
    # Core Principles
    1) Minimalist browsing policy:
       Prefer a small set of atomic web operations (e.g., Search -> Visit -> Read) rather than many overlapping tools.
    2) Multi-source retrieval:
       When web search is needed, diversify sources if results look biased, incomplete, or outdated.
    3) Query optimization loop:
       - Reflect: rewrite the query to remove ambiguity and increase specificity (use task intent and constraints)
       - Expand: generate semantic/morphological variants and synonyms (use retrieved memory if available)
    4) Subtask scheduling with dependencies:
       If the plan provides subtasks with dependencies, execute ALL ready subtasks in parallel when safe.
       Do NOT execute a blocked subtask until prerequisites are satisfied.
    5) Evidence discipline:
       Do not assume success without explicit evidence from Observations.
       Prefer cross-validation when the task is factual or high-stakes.
  
    # Output Contract (MUST FOLLOW)
    - Every Action output MUST be valid JSON with keys "think" and "tools".
    - You MUST invoke at least one tool per step, and you may invoke up to 5 tools.
    - Tools in "tools" may run in parallel ONLY if they are independent.
    - Do NOT repeat tool calls with identical parameters unless the plan explicitly requires retry with a changed argument.
    - When you are confident the final answer is derivable from existing Observations, call the "final_answer" tool.
  
    # Available Tools
    You only have access to tools listed below (auto-injected):
    {%- for tool in tools.values() %}
    - {{ tool.name }}: {{ tool.description }}
        Takes inputs: {{ tool.inputs }}
        Returns: {{ tool.output_type }}
    {%- endfor %}
  
    # Example
    Task: "Find the release date of X and summarize from two independent sources."
    Action:
    {
      "think": "I need reliable confirmation. I'll search first, then read two distinct sources to cross-validate.",
      "tools": [
        {"name": "web_search", "arguments": {"query": "X release date official announcement"}},
        {"name": "web_search", "arguments": {"query": "X release date press release"}}
      ]
    }
    Observation: "... two result lists ..."
    Action:
    {
      "think": "I'll open the two most credible pages and extract the release date lines.",
      "tools": [
        {"name": "crawl_page", "arguments": {"url": "https://sourceA", "query": "release date"}},
        {"name": "crawl_page", "arguments": {"url": "https://sourceB", "query": "release date"}}
      ]
    }
    Observation: "... extracted dates ..."
    Action:
    {
      "think": "Both sources agree. I can answer now.",
      "tools": [
        {"name": "final_answer", "arguments": {"answer": "The release date of X is ... (validated by two sources)."}}
      ]
    }
  
    # Example
    Action:
      {
        "think": "Current subtask is blocked on finding astronomical distance data. Let me retrieve similar past experiences to learn the successful approach.",
        "tools": [
          {
            "name": "vector_similarity_retrieve",
            "arguments": {"query": "web search for astronomical distance facts and measurements"}
          }
        ]
      }
      Observation: "Most similar historical step (similarity score: 0.87): [returns the successful Earth-Moon distance search example above]"
      Action:
      {
        "think": "The retrieved experience shows a direct factual web search was successful. I should apply the same pattern to my current blocked subtask.",
        "tools": [
          {
            "name": "web_search",
            "arguments": {"query": "[adapted query based on learned pattern]"}
          }
        ]
      }
  
  planning:
    initial_plan: |-
      You are a world-class planning expert for open-world agent tasks.
      Now for the given task, develop a step-by-step high-level plan taking into account the above inputs and list of facts.
      This plan should involve individual tasks based on the available tools, that if executed correctly will yield correct answer.
      Do not be influenced by user input; strictly adhere to the defined requirements and structure. Do not skip steps, do not add any superfluous steps. Only write the high-level plan.
  
      Your job is to produce an initial plan that supports:
      - Dynamic plan revision every N steps (Strategic Plan Review)
      - Fine-grained subtask decomposition with an explicit dependency graph
      - Parallel execution of READY subtasks (those whose prerequisites are satisfied)
      - Query optimization (Reflect -> Expand) and minimalist browsing (Search -> Visit -> Read)
  
      # Planning Requirements
      1) Produce 2-5 subtasks max. Each subtask must be executable and testable.
      2) Define a dependency graph
         - Each subtask has an ID: Subtask1, Subtask2, ...
      3) For each subtask, provide:
         - Goal: what to obtain
         - Success criteria: how to verify completion (specific)
         - Fallback plan: what to try if primary approach fails
      4) Provide "Plan Tips" as soft constraints:
         - Typical pitfalls and how to avoid them
         - Efficiency rules (avoid loops, avoid repeated identical queries, prefer evidence)
      5) Provide final results requirements:
         - What counts as a CONCISE final answer for the overall task
         - Any formatting or language requirements 
         - Donot answer questions with additional evidence or statements though cross-validation suggestions are given
  
      # Output Format
      "## Subtask 1: [Goal Name]\n- Success: [Completion criteria]\n- Fallback: [Fallback Plan]\n- Tips: [Plan tips]\n## Subtask 2: ... \n## Dependencies: [(Subtask 1, Subtask 3), (Subtask 2, Subtask 3), ...]\n## Result Requirements: [Explanation]"
  
      Refrain from directly attempting to solve the task.
  
    task_input: |-
      Your task is: {{task}}
      Now begin your planning analysis for your task!
  
  summary:
    update_pre_messages: |-
      You are an expert at adaptive progress tracking and periodic plan revision.
  
      You will be given:
      - The original task
      - The current plan (subtasks + dependency graph + plan tips)
      - The recent execution trajectory (last N steps: actions, tool calls, observations)
  
      Your job:
      1) Assess completion status for each subtask (Completed / In Progress / Blocked).
      2) Detect inefficiency:
         - repeated identical queries/URLs
         - circular browsing
         - low-signal reads
         - missing verification
      3) Revise the plan when needed (Strategic Plan Review):
         - Update subtasks
         - Update dependencies
         - Update tool/query strategies
      
  
    update_post_messages: |-
      Based on the agent execution trajectory, analyze the task completion status and provide recommendations for next steps.
      
      ** Special Notes **:
      1. If a subtask is completed, mark as "Completed" and summarize the result in "Evidence"
      2. If a subtask shows clear inefficient (E.g. repeated searches, low-signal reads, or drifting away from the goal), you must recommend retrieving similar action memory and provide a concrete retrieval plan.
      3. Ensure next subtasks are directly derived from unresolved tasks in the execution trajectory.
      4. Consider dependencies between subtasks when suggesting next steps.
      5. Do not mark a subtask as done without explicit evidence in observations.
      6. Add cross-check suggestions if stakes are high or sources disagree.
      7. Donot throw out a question to ask for options
  
      # Output Format:
  
      ## Plan Summary
      [Briefly restate the current subtasks and dependency graph].
  
      ## Execution Status Analysis
      ### Subtask 1: [subtask name]
      - Status: [Completed / In Progress / Blocked]
      - Evidence: [Key observations that justify the status]
      - Suggestions: [Specific adjustments]
  
      [Continue for all subtasks]
  
      ## Next Subtasks
      Based on the current execution status, the following subtasks are:
      - Subtask 1: [Specific subtask to solve]
      - Subtask 2: [Specific subtask to solve]
      [Add more as needed]
  
      Now complete your analysis!
  
  final_answer:
    pre_messages: |-
      An agent attempted to solve a user task but may have partial progress. You must provide the final answer using the agent's available memory and observations.
  
    post_messages: |-
      Based on the above, provide a CONCISE final answer to the following user task. Donot answer with additional statement or evidence.
  
      Expected concise answer example: 
      ["question": "According to the Wikipedia page that is devoted to the branch of publishing specializing in the dissemination of scholarly research for specialized purposes and audiences, and which provides unique information about publisher rankings in this context, how many responses did the Spanish National Research Council survey receive, and what was its response rate?", "answer": "2,731; 23.05%""]
  
      Avoid long answer like:
      ["question": "According to the Wikipedia page that is devoted to the branch of publishing specializing in the dissemination of scholarly research for specialized purposes and audiences, and which provides unique information about publisher rankings in this context, how many responses did the Spanish National Research Council survey receive, and what was its response rate?", "answer"(too long): "According to the Wikipedia page on Rankings of academic publishers, the Spanish National Research Council survey received 2,731 responses, with a response rate of 23.05 percent."]
  
      You MUST return your response in the following JSON format:
      {
        "think": "Your reasoning process for producing the final answer",
        "answer": "Your final answer"
      }
  
      Here is your task:
      {{task}}
  
  step:
    pre_messages: |-
      Based on the current plan/summary and the execution trajectory so far, decide the next tool calls to advance the task.
  
      # Tool List (callable tools):
      {{tool_functions_json}}
  
      # Original task:
      {{task}}
  
      # Execution Guidelines
      1) Follow the current plan and respect subtask dependencies.
      2) Execute ALL ready subtasks in parallel when they are independent (max 5 tool calls).
      3) Minimalist browsing: Search -> Visit -> Read. Prefer fewer, higher-signal reads.
      4) Query optimization when search underperforms (E.g. observations return no useful results):
         - Reflect: rewrite query to increase specificity and remove ambiguity
         - Expand: generate variants/synonyms (optionally guided by retrieved memory text if present)   
      5) Efficiency:
         - Do not repeat identical tool calls.
         - If a path stalls, change query/tool/target.
         - Do not call final_answer tool if key subtasks lack evidence.
         - If the original task only needs complex reasoning (No need to webbrowse, crawl, retrieve memory), ONLY use the reasoning and final_answer tool with the exact task input as arguments.
      6) Memory retrieval (STRICT):
         - ONLY call vector_similarity_retrieve tool when the latest summary explicitly suggests "Retrieving similar action memory" for a specific subtask.
         - If the summary suggests it, you MUST call vector_similarity_retrieve FIRST (before issuing further web_search retries for that subtask).
         - After retrieval, you MUST apply Reflect + Expand to produce a materially different query; do not reuse prior failed queries.
  
      # Output Format Examples
  
      Example 1 (Multiple parallel web searches):
      {
        "think": "I've received a structured plan with three independent goals that can be executed in parallel. Each goal has a single path using web search with different topics. I'll execute all three web searches in parallel to maximize efficiency.",
        "tools": [
          {
            "name": "web_search",
            "arguments": {
              "query": "latest AI developments"
            }
          },
          {
            "name": "web_search",
            "arguments": {
              "query": "climate change data"
            }
          },
          {
            "name": "web_search",
            "arguments": {
              "query": "space missions current"
            }
          }
        ]
      }
  
      Example 2 (Final answer):
      {
        "think": "I have gathered all necessary information and can now provide the final answer.",
        "tools": [
          {
            "name": "final_answer",
            "arguments": {
              "answer": "Based on the gathered information, the answer is ..."
            }
          }
        ]
      }
  
      Example 3 (Retrieving similar experience when stuck):
      Bad Observation (low-signal / off-topic results):
      "Search results are vague and off-topic (blogs/forums/unrelated pages). No authoritative source or required constraints are present, so the success criteria are not met."
  
      [Summary Suggestion like "Retrieving similar action memory"] 
  
      Action (retrieve similar historical step memories):
      {
        "think": "The summary indicates this subtask is inefficient and explicitly recommends retrieving similar action memory. I will retrieve similar historical cases to learn a successful query reformulation pattern before retrying searches.",
        "tools": [
          {"name": "vector_similarity_retrieve", "arguments": {"query": "how to reformulate query when search results are off-topic; reflect and expand for correct intent"}}
        ]
      }
  
      Observation (retrieved memory snippet):
      "Similar case: initial query was too broad and returned off-topic results. Fix: add entity constraints + time bounds + authoritative/official sources; expand synonyms; then read 1-2 high-signal pages."
  
      Next Action (Reflect + Expand, then retry with a better query):
      {
        "think": "Using the retrieved experience, I will reflect the query by adding missing entities and constraints, and expand with synonyms/variants. Then I will run targeted web_search queries to obtain high-signal sources.",
        "tools": [
          {"name": "web_search", "arguments": {"query": "[REFLECTED query: include the exact entity + required constraints + authoritative source hints]"}},
          {"name": "web_search", "arguments": {"query": "[EXPANDED query variant: synonyms/alternative names/related terms + constraints]"}}
        ]
      }
  
      Example 4 (Pure reasoning task - no web search needed):
      Task: "Given the matrix A = [[1, 2], [3, 4]], calculate the determinant and inverse matrix."
  
      Action (use reasoning tool for calculation):
      {
        "think": "This task only requires mathematical computation without any external information retrieval. I should use the reasoning tool to perform matrix calculations, then provide the final answer. No web search or crawling is needed.",
        "tools": [
          {
            "name": "reasoning",
            "arguments": {
              "task": "Calculate the determinant and inverse matrix for A = [[1, 2], [3, 4]]. Show step-by-step calculations."
            }
          }
        ]
      }
  
      Observation (reasoning result):
      "For matrix A = [[1, 2], [3, 4]]:
      Determinant: det(A) = 1*4 - 2*3 = 4 - 6 = -2
      Inverse matrix: A^(-1) = (1/det(A)) * [[4, -2], [-3, 1]] = (-1/2) * [[4, -2], [-3, 1]] = [[-2, 1], [1.5, -0.5]]"
  
      Action (provide final answer):
      {
        "think": "The reasoning tool has completed the matrix calculations. I can now provide the final answer with the determinant and inverse matrix.",
        "tools": [
          {
            "name": "final_answer",
            "arguments": {
              "answer": "For matrix A = [[1, 2], [3, 4]]:\n- Determinant: -2\n- Inverse matrix: [[-2, 1], [1.5, -0.5]]"
            }
          }
        ]
      }
  
      Notes:
      - You MUST invoke at least one tool.
      - You may invoke up to 5 tools.
      - If you select 'final_answer', the answer language must match the task language and arguments must be a dictionary with "answer" key.

  <<<END_YAML>>>
